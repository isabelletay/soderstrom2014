---
title: "Replication of Judgments of Learning as Memory Modifiers by Soderstrom, N.C., Clark, C. T., Halamish, V. & Bjork, E. L. (2015, Journal of Experimental Psychology: Learning, Memory, and Cognition)"
author: "Tay, Isabelle, Q. Y. (Graduate School of Education, Stanford University, 485 Lasuen Mall, Stanford, CA 94305)"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  html_document:
    toc: yes
    toc_depth: 3
    toc_float:
      collapsed: false
---

<!-- Replication reports should all use this template to standardize reporting across projects.  These reports will be public supplementary materials that accompany the summary report(s) of the aggregate results. -->

```{r}
library(tidyverse)
```


##Introduction


Metacognition is the cognition, or awareness, of one's own thought processes. A subset of metacognition, metamemory refers to "the processes and structures whereby people are able to examine the content of their memories, either prospectively or retrospectively, and make judgments or commmentaries about them" (Metcalfe & Dunlosky, 2008). The chosen study by Soderstrom and colleagues (2015) focused on whether metacognitive judgments of learning (JOLs) affects memory of studied word-pairs, which may be strongly-related versus weakly-related (Experiment 1a), or strongly-related versus unrelated (Experiment 1b). 

Experiment 1b was chosen as it was run on Amazon Mechanical Turk participants. In Experiment 1b, participants were split equally into a judgment and no-judgment condition by random assignment. The authors demonstrated that during the study phase, the mean magnitude of JOls of strongly related pairs was significantly larger than that of unrelated pairs, showing that "the relatedness between cue-target words seems to be the cue on which participants largely based their JOLs". During the test phase, there was a significant main effect of cue-target association (strongly related pairs were recalled at a higher rate than unrelated pairs), but no significant effect of judgment condition. However, there was a significant interaction between cue-target association and judgment condition: "planned comparisons confirm[ed] cue-recall to be greater for judged strongly related pairs than for nonjudged strongly related pairs, but not for judged versus nonjudged unrelated pairs". Hence, the authors concluded that participants made use of the intrinsic and salient cue of relatedness as the basis for making their JOLs, "resulting in the strengthening of that association when such information was easily discernable (i.e., for the strongly related pairs...), but to a lesser extent, if at all, when such information was not east to discern (i.e., for the weakly related and unrelated pairs...). 


I chose this study because of my research goals: I hope to find effective interventions (which may be motivational or cognitive) in enhancing memory. As a social psychologist, I have limited experience in studies in cognition. Hence, I chose this study precisely because of the opportunities for learning something new but relevant to my research goals.

[Here is the original paper.](http://psycnet.apa.org/fulltext/2014-56008-001.pdf)

The main challenges for me would be obtaining the appropriate word pairs from the prescribed database and classifying them in  strongly-related or weakly-related categories in R. Also, other challenges include setting up the test, which I plan to do on Qualtrics, and using MTurk, RStudio, and other software in this course for the first time.


##Methods

#Participants, materials, and procedure


###Power Analysis

<!-- Original effect size, power analysis for samples to achieve 80%, 90%, 95% power to detect that effect size.  Considerations of feasibility for selecting planned sample size. -->

###Planned Sample

Sixty Participants (~30 women, ~30 men; median age = 32 years, range = 18- 67 years) were recruited online via Amazon's Mechanical Turk and were paid $1.00 to complete the study. Participants lived in the United States and were fluent English speakers. 

###Materials

```{r}
#If the first file exists, don't run the code for the rest of the data files. If the file does not exist, download all the data files from the internet.
if (!file.exists("../data/word_pairs0.csv")) {
  download.file("http://w3.usf.edu/FreeAssociation/AppendixA/Cue_Target_Pairs.A-B", "../data/word_pairs0.csv")
  download.file("http://w3.usf.edu/FreeAssociation/AppendixA/Cue_Target_Pairs.C", "../data/word_pairs1.csv")
  download.file("http://w3.usf.edu/FreeAssociation/AppendixA/Cue_Target_Pairs.D-F", "../data/word_pairs2.csv")
  download.file("http://w3.usf.edu/FreeAssociation/AppendixA/Cue_Target_Pairs.G-K", "../data/word_pairs3.csv")
  download.file("http://w3.usf.edu/FreeAssociation/AppendixA/Cue_Target_Pairs.L-O", "../data/word_pairs4.csv")
  download.file("http://w3.usf.edu/FreeAssociation/AppendixA/Cue_Target_Pairs.P-R", "../data/word_pairs5.csv")
  download.file("http://w3.usf.edu/FreeAssociation/AppendixA/Cue_Target_Pairs.S", "../data/word_pairs6.csv")
  download.file("http://w3.usf.edu/FreeAssociation/AppendixA/Cue_Target_Pairs.T-Z", "../data/word_pairs7.csv")
}
word_pairs = do.call(
  rbind, lapply(paste("../data/word_pairs", 0:7, ".csv", sep=""), function(filename) {
    #comment.char removes anything that starts with <, which is the <HTML> text in the top of each data file
    df = read.csv(filename, header = T, comment.char = "<")
    #There was a typo error in the ...2.csv file
    if ("TRF" %in% names(df)) {
      df = df %>% rename(TFR = TRF)
    }
  })
)
```

```{r}
# select 30 strongly related pairs and 30 unrelated pairs
hist(word_pairs$FSG)
max(word_pairs$FSG)
min(word_pairs$FSG)
#a higher number means the more strongly related 
quantile(word_pairs$FSG, 0.1)
quantile(word_pairs$FSG, 0.9)
weak_pairs = word_pairs %>% filter(FSG < quantile(FSG, .1))
random_weak_pairs = select(weak_pairs, "CUE", "TARGET")
#obtain 30 random weakly related pairs (sample from dataframe)
random_weak_pairs[sample(nrow(random_weak_pairs), 30), ] 

```

```{r}
strong_pairs = word_pairs %>% filter(FSG > quantile(FSG, 0.9))
random_strong_pairs = select(strong_pairs, "CUE", "TARGET")
#obtain 30 random strongly related pairs
random_strong_pairs[sample(nrow(random_strong_pairs), 30), ] 
```

The word-pairs used in this study were obtained from the original study's referenced database [(Nelson, McEvoy, & Schreiber, 1998)](http://w3.usf.edu/FreeAssociation/). The authors did not describe the procedure for obtaining word pairs nor state the specific numerical cut-off values that categorized strongly related and unrelated word pairs. As we wanted to replicate the original study's general finding which compared memory of strongly to weakly related word pairs, we obtained the word pairs by randomly selecting 30 weakly related and 30 strongly related word pairs from the words falling into the tenth and ninetieth percentile of the relatedness index respectively. 

###Procedure	

Following Experiment 1b in the study by Soderstrom and colleagues (2015), a random half of the 60 participants were assigned to a judgment condition, and the other half were assigned to a no-judgment condition. During the study phase, 60 cue-target word pairs were studied for a later memory test, of which half were strongly related and half were unrelated, according to Nelson, McEvoy, and Schreiber (1998). These individual pairs were exposed in a randomized order for 8s on a computer screen. "During exposure of each pair, the [30] participants assigned to the judgment condition were required to make a JOL to that pair by estimating the likelihood, on a 0-100% scale, of successfully recalling the pair on a later test, being prompted to do so half way through the exposure duration (i.e. after 4 s); whereas, the [30] participants assigned to the no-judgment condition made no JOLs during the 8 s exposure of each pair. Following the presentation of all pairs, participants played Tetris for 3 min and were then given a cued-recall test", in which they were presented with each of the 60 cue-words individually for 5 s in a randomized order and asked to type in the target-word within that time.


###Analysis Plan

<!--Can also quote directly, though it is less often spelled out effectively for an analysis strategy section.  The key is to report an analysis strategy that is as close to the original - data cleaning rules, data exclusion rules, covariates, etc. - as possible.  

**Clarify key analysis of interest here**  You can also pre-specify additional analyses you plan to do. -->

###Differences from Original Study

<!-- Explicitly describe known differences in sample, setting, procedure, and analysis plan from original study.  The goal, of course, is to minimize those differences, but differences will inevitably occur.  Also, note whether such differences are anticipated to make a difference based on claims in the original article or subsequent published research on the conditions for obtaining the effect. -->

### Methods Addendum (Post Data Collection)

<!-- You can comment this section out prior to final report with data collection. -->

#### Actual Sample
  <!-- Sample size, demographics, data exclusions based on rules spelled out in analysis plan -->

#### Differences from pre-data collection methods plan
  <!-- Any differences from what was described as the original plan, or ???none???. -->
In Experiment 1a, Soderstrom and colleages (2015) demonstrated that among 40 undergraduate students, and using the MRC Psycholinguistic database, cued-recall for judged strongly related pairs was greater than for nonjudged strongly related pairs, but not for judged versus nonjudged weakly related pairs. Experiment 1b demonstrated the same finding in comparing strongly related to unrelated word pairs, among 60 participants from Amazon Mechanical Turk, using the database from Nelson, McEvoy & Schreiber (1998). As the authors did not specify the procedure for obtaining word pairs, and we wanted to generalize the finding, we obtained strongly and weakly related word pairs from the Nelson, McEvoy & Schreiber (1998) database by randomly sampling from word pairs from the tenth and ninetieth percentiles of the relatedness index.

##Results


### Data preparation

<!--Data preparation following the analysis plan. --> 
	
```{r include=F}
###Data Preparation

####Load Relevant Libraries and Functions

####Import data

#### Data exclusion / filtering

#### Prepare data for analysis - create columns etc.
```

### Confirmatory analysis

<!-- The analyses as specified in the analysis plan.  

*Side-by-side graph with original graph is ideal here* -->

###Exploratory analyses

<!-- Any follow-up analyses desired (not required).   -->

## Discussion

### Summary of Replication Attempt

<!-- Open the discussion section with a paragraph summarizing the primary result from the confirmatory analysis and the assessment of whether it replicated, partially replicated, or failed to replicate the original result.   -->

### Commentary

<!-- Add open-ended commentary (if any) reflecting (a) insights from follow-up exploratory analysis, (b) assessment of the meaning of the replication (or not) - e.g., for a failure to replicate, are the differences between original and present study ones that definitely, plausibly, or are unlikely to have been moderators of the result, and (c) discussion of any objections or challenges raised by the current and original authors about the replication attempt.  None of these need to be long.--> 
